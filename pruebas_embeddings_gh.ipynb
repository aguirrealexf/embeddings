{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías y variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import tiktoken\n",
    "\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos las variables de entorno necesarias\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example requires environment variables named \"OPEN_AI_KEY\" and \"OPEN_AI_ENDPOINT\"\n",
    "# Your endpoint should look like the following https://YOUR_OPEN_AI_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_key = os.environ.get('AZURE_OPENAI_KEY')\n",
    "openai.api_base =  os.environ.get('AZURE_OPENAI_ENDPOINT')\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-03-15-preview'\n",
    "\n",
    "# This will correspond to the custom name you chose for your deployment when you deployed a model.\n",
    "deployment_id='chatv2'\n",
    "GPT_MODEL= 'gpt-3.5-turbo'\n",
    "CHAT_GPT_MODEL='chat'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_heading(paragraph):\n",
    "    \"\"\"Controla el tipo de \"heading\" del párrafo.\n",
    "\n",
    "    :param párrafo:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    type_heading = ''\n",
    "    \n",
    "    if paragraph.style.name.startswith('Heading 1'):\n",
    "        type_heading = 'heading1'\n",
    "    elif paragraph.style.name.startswith('Heading 2'):\n",
    "        type_heading = 'heading2'\n",
    "    elif paragraph.style.name.startswith('Heading 3'):\n",
    "        type_heading = 'heading3'\n",
    "    else:\n",
    "        type_heading = 'other'\n",
    "    \n",
    "    return type_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_document_sections(document):\n",
    "    \"\"\"Por cada sección de \"headed\", genera una secuencia de párrafos.\n",
    "    Cada secuencia comienza con el párrafo \"headed\", seguido del texto normal del párrafo.\n",
    "\n",
    "    :param document: Current Comet Issue\n",
    "    :return: an article\n",
    "    \"\"\"\n",
    "    paragraphs = [document.paragraphs[0]]\n",
    "    #paragraphs = []\n",
    "    for idx, paragraph in enumerate(document.paragraphs[1:]):\n",
    "        if is_heading(paragraph) == 'heading1':\n",
    "            yield paragraphs\n",
    "            paragraphs = [paragraph]\n",
    "            continue\n",
    "        elif is_heading(paragraph) == 'heading2':\n",
    "            yield paragraphs\n",
    "            paragraphs = [paragraph]\n",
    "            continue\n",
    "        elif is_heading(paragraph) == 'heading3':\n",
    "            yield paragraphs\n",
    "            paragraphs = [paragraph]\n",
    "            continue\n",
    "        else:\n",
    "            paragraphs.append(paragraph)\n",
    "    yield paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_from_paragraphs(paragraphs):\n",
    "    \"\"\"Itera entre los diferentes párrafos, identificando los artículos, y haciendo un split de la documentación.\n",
    "    El resultado final se almacena en un DF:\n",
    "\n",
    "    :param paragraphs: Article text\n",
    "    :return: DF whit single articule for each row.\n",
    "    \"\"\"\n",
    "    new_doc = Document()\n",
    "    list_contenido = []\n",
    "\n",
    "    for counter, words in enumerate(paragraphs):\n",
    "        new_content = words.text\n",
    "        list_contenido.append(new_content)\n",
    "        new_doc.add_paragraph(new_content)\n",
    "    print('----------- FIN PROCESAR NUEVO CONTENIDO-----------')\n",
    "    text = '\\n'.join(list_contenido)\n",
    "    df_spliteado.loc[len(df_spliteado),'content'] = text\n",
    "\n",
    "    #new_doc.save(paragraphs[0].text + '.docx')     # esta línea nos permite guardar cada articulo generado en un documento separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Devuelve la cantidad de tokens de un string\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    #relatedness_fn=lambda x, y: 1 - openai.spatial.distance.cosine(x, y),\n",
    "    relatedness_fn=lambda x, y: cosine_similarity(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Devuelve una lista de artículos relacionados, ordenados del mas relevante al menos relevante.\"\"\"\n",
    "    \n",
    "    query_embedding = get_embedding(query, engine = deployment_id)\n",
    "    \n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"content\"], relatedness_fn(query_embedding, row[\"vector_embeding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de prueba\n",
    "strings, relatednesses = strings_ranked_by_relatedness(\"tipos de inversiones\", df_spliteado, top_n=5)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Devuelve el msj formateado para GPT, con los artículos relevantes relacionados encontrados.\"\"\"\n",
    "    \n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df, top_n=5)\n",
    "    introduction = 'Utilizar los siguientes artículos sobre los Instructivos y Procesos para seguro de retiro, para contestar las subsecuentes consultas. Si la respuesta no se encuentra entre los artículos, responder \"No se encontró ninguna información sobre la consulta.\"'\n",
    "    question = f\"\\n\\nConsulta: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nArtículos sobre seguros de retiro:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df_spliteado,\n",
    "    model_query: str = GPT_MODEL,\n",
    "    model: str = CHAT_GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Retorna la respuesta a la consulta realizada, utilizando GPT y los artículos relevantes encontrados.\"\"\"\n",
    "    \n",
    "    message = query_message(query, df, model=model_query, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Actúa como un asesor que responde consultas sobre Seguros de Retiro. Siempre responder en español.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comenzamos con el \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento del Documento a analizar:\n",
    "\n",
    "- Definimos el documento a procesar.\n",
    "- Creamos el DataFrame que almacenara los artículos procesados.\n",
    "- Iteramos todo el documento, completando el DataFrame con los artículos encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el Documento a procesar (para este ejemplo, se realiza un analisis a nivel de \"headed\").\n",
    "# Definimos el DF que almacenara los datos procesados.\n",
    "\n",
    "document = Document('./Doc_2.docx')\n",
    "df_spliteado = pd.DataFrame(columns=['content', 'len_token', 'vector_embeding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "----------- FIN PROCESAR NUEVO CONTENIDO-----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 35 entries, 0 to 34\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   content          35 non-null     object\n",
      " 1   len_token        0 non-null      object\n",
      " 2   vector_embeding  0 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "                                             content len_token vector_embeding\n",
      "0  Procedimiento - Responsabilidades del puesto\\n...       NaN             NaN\n",
      "1  TRATAMIENTO DE LAS COMUNICACIONES\\n\\nPor solic...       NaN             NaN\n",
      "2                               PREGUNTAS FRECUENTES       NaN             NaN\n",
      "3  Asesoramiento del Producto\\nPrevención Retiro ...       NaN             NaN\n",
      "4  \\nPodés armarlo a tu medida:\\nDecidís en qué m...       NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "# iteramos por todos los párrafos del documento, y completamos el DF con la información procesada.\n",
    "\n",
    "for paragraphs in iterate_document_sections(document):\n",
    "    create_document_from_paragraphs(paragraphs)\n",
    "\n",
    "print(df_spliteado.info())\n",
    "print(df_spliteado.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Tokens y Embedding\n",
    "\n",
    "- Se completa y controla la cantidad de tokens de cada articulo (note: el modelo de Embedding tiene un limite máximo de tokens como input).\n",
    "- Completamos el DF con los vectores de Embedding correspondiente a cada articulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los tokens para cada artículo creado.\n",
    "\n",
    "df_spliteado['len_token'] = df_spliteado['content'].apply(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>len_token</th>\n",
       "      <th>vector_embeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRATAMIENTO DE LAS COMUNICACIONES\\n\\nPor solic...</td>\n",
       "      <td>1560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asesoramiento del Producto\\nPrevención Retiro ...</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Procedimiento - Responsabilidades del puesto\\n...</td>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nPodés armarlo a tu medida:\\nDecidís en qué m...</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PREGUNTAS FRECUENTES</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  len_token  \\\n",
       "1  TRATAMIENTO DE LAS COMUNICACIONES\\n\\nPor solic...       1560   \n",
       "3  Asesoramiento del Producto\\nPrevención Retiro ...        249   \n",
       "0  Procedimiento - Responsabilidades del puesto\\n...        233   \n",
       "4  \\nPodés armarlo a tu medida:\\nDecidís en qué m...        115   \n",
       "2                               PREGUNTAS FRECUENTES          8   \n",
       "\n",
       "  vector_embeding  \n",
       "1             NaN  \n",
       "3             NaN  \n",
       "0             NaN  \n",
       "4             NaN  \n",
       "2             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spliteado.head().sort_values(['len_token'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el vector de Embedding para cada artículo.\n",
    "\n",
    "df_spliteado['vector_embeding'] = df_spliteado['content'].apply(lambda x: get_embedding(x, engine = deployment_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>len_token</th>\n",
       "      <th>vector_embeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Procedimiento - Responsabilidades del puesto\\n...</td>\n",
       "      <td>233</td>\n",
       "      <td>[-0.017123669385910034, 0.0010063608642667532,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRATAMIENTO DE LAS COMUNICACIONES\\n\\nPor solic...</td>\n",
       "      <td>1560</td>\n",
       "      <td>[-0.012864670716226101, 0.0014471879694610834,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PREGUNTAS FRECUENTES</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.005458911415189505, -0.017592333257198334, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asesoramiento del Producto\\nPrevención Retiro ...</td>\n",
       "      <td>249</td>\n",
       "      <td>[-0.011354345828294754, -0.024713190272450447,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nPodés armarlo a tu medida:\\nDecidís en qué m...</td>\n",
       "      <td>115</td>\n",
       "      <td>[-0.006575466133654118, -0.024058355018496513,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  len_token  \\\n",
       "0  Procedimiento - Responsabilidades del puesto\\n...        233   \n",
       "1  TRATAMIENTO DE LAS COMUNICACIONES\\n\\nPor solic...       1560   \n",
       "2                               PREGUNTAS FRECUENTES          8   \n",
       "3  Asesoramiento del Producto\\nPrevención Retiro ...        249   \n",
       "4  \\nPodés armarlo a tu medida:\\nDecidís en qué m...        115   \n",
       "\n",
       "                                     vector_embeding  \n",
       "0  [-0.017123669385910034, 0.0010063608642667532,...  \n",
       "1  [-0.012864670716226101, 0.0014471879694610834,...  \n",
       "2  [0.005458911415189505, -0.017592333257198334, ...  \n",
       "3  [-0.011354345828294754, -0.024713190272450447,...  \n",
       "4  [-0.006575466133654118, -0.024058355018496513,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spliteado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de consultas realizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La Compañía invierte el dinero en Obligaciones Negociables, Fondos comunes de inversión, títulos públicos, plazos fijos y otros, según lo determinado por la SSN y dentro del porcentaje máximo permitido.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('¿En que se invierte mi dinero?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
